{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wand in c:\\programdata\\anaconda3\\lib\\site-packages (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.16.5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from wand.color import Color \n",
    "from wand.image import Image as WandImage\n",
    "from wand.display import display\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"inputs/\", exist_ok = True)\n",
    "os.makedirs(\"outputs/\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_image(original_frame, cropped_face, face_dimension, face_center, output_path):\n",
    "  print(cropped_face.shape, type(cropped_face),  cropped_face.dtype)\n",
    "  cv2.imshow(\"cropped face\", cropped_face)\n",
    "  print(\"original_frame\")\n",
    "  dst = cv2.imread(original_frame)\n",
    "  print(dst.shape, type(dst), dst.dtype)\n",
    "  ## Now, we create a mask for the face\n",
    "  src_mask = np.zeros(cropped_face.shape, cropped_face.dtype)\n",
    "  face_w, face_h = face_dimension\n",
    "  poly = np.array([[0,0], [face_w, 0], [face_w, face_h], [0, face_h]], np.int32)\n",
    "  cv2.fillPoly(src_mask, [poly], (255, 255, 255))\n",
    "\n",
    "  ## Now we are ready to call seamlessClone \n",
    "  output = cv2.seamlessClone(cropped_face, dst, src_mask, face_center, cv2.NORMAL_CLONE)\n",
    "  cv2.imwrite(output_path, output)\n",
    "  cv2.waitKey(0)\n",
    "  cv2.destroyAllWindows()\n",
    "  print(\"Final output: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dimension = (180, 300) #w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangle_face_coordinates = (   \n",
    "    ( 705.87203406,   34.74937345),\n",
    "    (678.39937345,  534.02796594),\n",
    "    (1177.67796594,  561.50062655),\n",
    "    (1205.15062655,   62.22203406)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cover:  small picture (just the face)\n",
    "template: big picture (al the frame)\n",
    "'''\n",
    "def transform(template_path, cover_path, rectangle_face_coordinates, face_dimension, output_path):\n",
    "    with WandImage(filename=template_path) as template:\n",
    "        cover_array = cv2.imread(cover_path) #, cv2.IMREAD_UNCHANGED)\n",
    "        cover_array_resized = cv2.resize(cover_array, (template.size[1], template.size[0]))      \n",
    "        with WandImage.from_array(cover_array_resized, channel_map=\"BGR\") as cover:\n",
    "            w, h = cover.size\n",
    "            print(f\"Size of original cover: {(w, h)}\")\n",
    "            print(f\"Size of cover resized: {(cover.size)}\")\n",
    "            print(f\"Size of template: {(template.size)}\")\n",
    "            cover.virtual_pixel = 'transparent'\n",
    "            source_points = (\n",
    "                  (0, 0),\n",
    "                  (0, h),\n",
    "                  (w, h),\n",
    "                  (w, 0)\n",
    "            )\n",
    "            order = chain.from_iterable(zip(source_points, rectangle_face_coordinates))\n",
    "            arguments = list(chain.from_iterable(order))\n",
    "            print(f\"arguments: {arguments}\")\n",
    "            cover.distort('perspective', arguments)\n",
    "            # cover.save(filename='./intermediate_outputs/face_in_perspective.jpg')\n",
    "            ###################################\n",
    "            ### Here, we crop just the face ###\n",
    "            x_center = int((rectangle_face_coordinates[0][0]+ rectangle_face_coordinates[2][0])/2)\n",
    "            y_center = int((rectangle_face_coordinates[0][1]+ rectangle_face_coordinates[2][1])/2)\n",
    "            face_w, face_h = face_dimension\n",
    "            print(f\"face_dimension: {face_dimension}\")\n",
    "            left = x_center - (face_w // 2)\n",
    "            top = y_center - (face_h // 2)\n",
    "            print(f\"left: {left}, top: {top}\")\n",
    "            cover.crop(left= left, top= top, width=face_w, height=face_h)\n",
    "            ##################################\n",
    "            pixels = np.array(cover.export_pixels(channel_map= 'BGR', storage='char'), dtype=\"uint8\").reshape((face_h, face_w, 3))\n",
    "            smooth_image(original_frame, pixels, face_dimension, (x_center, y_center), output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_frame = \"./inputs/original_frame.png\"\n",
    "aligned_sad_image = \"./inputs/newswoman_super_happy_face.jpg\"\n",
    "aligned_sad_image = \"./inputs/newswoman_sad_face.jpg\"\n",
    "output_path = \"./outputs/newswoman_output_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Size of original cover: (1080, 1920)\nSize of cover resized: (1080, 1920)\nSize of template: (1920, 1080)\narguments: [0, 0, 705.87203406, 34.74937345, 0, 1920, 678.39937345, 534.02796594, 1080, 1920, 1177.67796594, 561.50062655, 1080, 0, 1205.15062655, 62.22203406]\nface_dimension: (180, 300)\nleft: 851, top: 148\n(300, 180, 3) <class 'numpy.ndarray'> uint8\noriginal_frame\n(1080, 1920, 3) <class 'numpy.ndarray'> uint8\nFinal output: \n"
    }
   ],
   "source": [
    "transform(original_frame, aligned_sad_image, rectangle_face_coordinates, face_dimension, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with WandImage(filename=\"./intermediate_outputs/news_resized_test.jpg\") as function_resized, WandImage(filename=\"./inputs/newswoman_super_happy_face.jpg\") as self_resized :\n",
    "#     print(self_resized.size)\n",
    "#     self_resized.resize(1920, 1080)\n",
    "#     self_resized_pixels = self_resized.export_pixels(storage=\"char\")\n",
    "#     print(f\"num pixels for self_resized: {len(self_resized_pixels)}\")\n",
    "#     print(self_resized_pixels[:20])\n",
    "# #     print(self_resized.colors)\n",
    "#     print(self_resized.depth)\n",
    "    \n",
    "#     print()\n",
    "    \n",
    "#     print(function_resized.size)\n",
    "#     function_resized_pixels = function_resized.export_pixels(storage=\"char\")\n",
    "#     print(f\"num pixels for function_resized: {len(function_resized_pixels)}\")\n",
    "#     print(function_resized_pixels[:20])\n",
    "# #     print(function_resized.colors)\n",
    "#     print(function_resized.depth)\n",
    "    \n",
    "#     print()\n",
    "    \n",
    "#     print(max(abs(self_resized_pixels[i]-function_resized_pixels[i]) for i in range(len(self_resized_pixels))))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"resolution: {cropped_resolution}\")\n",
    "# cropped_face = np.array(cropped_face, dtype=\"uint8\").reshape(300, 180, 3)\n",
    "# cv2.imwrite(\"cropped_test.jpg\", cropped_face)\n",
    "# print(cropped_face[0][:10])\n",
    "# print(cropped_face.shape, cropped_face.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre = cv2.imread(\"./intermediate_outputs/cropped_face.jpg\")\n",
    "# print(pre[0][:10])\n",
    "# print(pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped_face_path = \"./intermediate_outputs/cropped_face.jpg\"\n",
    "# # cropped_face =\n",
    "# smooth_image(original_frame, cropped_face , face_dimension, center)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}